% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{00A0}{\nobreakspace}
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}
\usepackage{multirow}
\usepackage{appendix} \setcounter{tocdepth}{0}

\title{reduce Users Manual}
\date{October 07, 2016}
\release{X1.0.1}
\author{Kenneth Anderson}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\makeindex

\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\expandafter\def\csname PYG@tok@gd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gu\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@gt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PYG@tok@gs\endcsname{\let\PYG@bf=\textbf}
\expandafter\def\csname PYG@tok@gr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@cm\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@vg\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@m\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@mh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@cs\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@ge\endcsname{\let\PYG@it=\textit}
\expandafter\def\csname PYG@tok@vc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@il\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@go\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.20,0.20,0.20}{##1}}}
\expandafter\def\csname PYG@tok@cp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@gi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gh\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@ni\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.84,0.33,0.22}{##1}}}
\expandafter\def\csname PYG@tok@nl\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.13,0.44}{##1}}}
\expandafter\def\csname PYG@tok@nn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@no\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.38,0.68,0.84}{##1}}}
\expandafter\def\csname PYG@tok@na\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@nd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.33,0.33,0.33}{##1}}}
\expandafter\def\csname PYG@tok@ne\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.49}{##1}}}
\expandafter\def\csname PYG@tok@si\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.44,0.63,0.82}{##1}}}
\expandafter\def\csname PYG@tok@s2\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@vi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@nt\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.45}{##1}}}
\expandafter\def\csname PYG@tok@nv\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@s1\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@gp\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@sh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ow\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sx\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@bp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c1\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@kc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@mf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@err\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PYG@tok@mb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@ss\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.32,0.47,0.09}{##1}}}
\expandafter\def\csname PYG@tok@sr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.14,0.33,0.53}{##1}}}
\expandafter\def\csname PYG@tok@mo\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@mi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@o\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@kr\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@s\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@kp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@w\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PYG@tok@kt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.56,0.13,0.00}{##1}}}
\expandafter\def\csname PYG@tok@sc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@k\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@se\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sd\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZam{\char`\&}
\def\PYGZlt{\char`\<}
\def\PYGZgt{\char`\>}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\$}
\def\PYGZhy{\char`\-}
\def\PYGZsq{\char`\'}
\def\PYGZdq{\char`\"}
\def\PYGZti{\char`\~}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\begin{document}

\maketitle
\tableofcontents
\phantomsection\label{index-latex::doc}



\chapter{Introduction}
\label{intro:introduction}\label{intro:reduce-users-manual}\label{intro::doc}
This document is version 1.0 of the \code{reduce} Users Manual. This manual will
describe the usage of \code{reduce} as an application provided by the Gemini Observatory
Astrodata package suite. \code{reduce} is an application that allows users to invoke the
Gemini Recipe System to perform data processing and reduction on one or more
astronomical datasets.

This document presents details on applying \code{reduce} to astronomical datasets,
currently defined as multi-extension FITS (MEF) files, both through the application's
command line interface and the application programming interface (API). Details and
information about the \code{astrodata} package, the Recipe System, and/or the data
processing involved in data reduction are beyond the scope of this document and
will only be engaged when directly pertinent to the operations of \code{reduce}.


\section{Reference Documents}
\label{intro:reference-documents}\begin{itemize}
\item {} 
\emph{The Gemini Recipe System: a dynamic workflow for automated data reduction},
K. Labrie \emph{et al}, SPIE, 2010.

\item {} 
\emph{Developing for Gemini’s extensible pipeline environment}, K. Labrie,
C. Allen, P. Hirst, ADASS, 2011

\item {} 
\emph{Gemini's Recipe System; A publicly available instrument-agnostic pipeline
infrastructure}, K. Labrie et al, ADASS 2013.

\end{itemize}


\section{Overview}
\label{intro:overview}
As an application, \code{reduce} provides interfaces to configure and launch the
Gemini Recipe System, a framework for developing and running configurable data
processing pipelines and which can accommodate processing pipelines for arbitrary
dataset types. In conjunction with the development of \code{astrodata}, Gemini
Observatory has also developed the \code{gemini\_instruments} and \code{GeminiDR}
packages, the code base currently providing abstraction of, and processing for,
Gemini Observatory astronomical observations.

In Gemini Observatory's operational environment ``on summit,'' \code{reduce},
\code{astrodata}, and the \code{gemini\_instruments} packages provide a currently defined,
near-realtime, quality assurance pipeline, the so-called QAP. \code{reduce} is used
to launch this pipeline on newly acquired data and provide image quality metrics
to observers, who then assess the metrics and apply observational decisions on
telescope operations.

Users unfamiliar with terms and concepts heretofore presented should consult
documentation cited in the previous sections (working on the Recipe System User
Manual).


\section{Glossary}
\label{intro:glossary}\begin{quote}

\textbf{adcc} -- Automatated Data Communication Center. Provides  HTTP
service for moinitoring QA metrics produced during pipeline operations.
This is run externally to \code{reduce.} Users need not know about or invoke
the \code{adcc} for \code{reduce} operations.

\textbf{astrodata} (or Astrodata) -- part of the \textbf{gemini\_python} package suite
that defines the dataset abstraction layer for the Recipe System.

\textbf{AstroData} -- not to be confused with \textbf{astrodata}, this is the main class
of the \code{astrodata} package, and the one most users and developers will
interact with at a programmatic level.

\textbf{AstroData tags} -- Astrodata tags Represents a data classification. A dataset
will be classified by a number of types that describe both the data and its
processing state. For example, a typical unprocessed GMOS image would have a
set of tags like

set({[}'RAW', `GMOS', `GEMINI', `SIDEREAL', `UNPREPARED', `IMAGE', `SOUTH'{]})
(see \textbf{tags} below).

\textbf{Descriptor} -- Represents a high-level metadata name. Descriptors allow
access to essential information about the data through a uniform,
instrument-agnostic interface to the FITS headers.

\textbf{gemini\_python} -- A suite of packages comprising \textbf{astrodata},
\textbf{gemini\_instruments}, the \textbf{recipe system} and \textbf{gempy}, all of which
provide the full functionality needed to run recipe  pipelines on
observational datasets.

\textbf{gempy} -- a \textbf{gemini\_python} package comprising gemini specific functional
utilities.

\textbf{MEF} -- Multiple Extension FITS, the standard data format not only for
Gemini Observatory but many observatories.

\textbf{primitive} -- A function defined within an \textbf{GeminiDR} package that
performs actual work on the passed dataset. Primitives observe tightly
controlled interfaces in support of re-use of primitives and recipes for
different types of data, when possible. For example, all primitives called
\code{flatCorrect} must apply the flat field correction appropriate for the data’s
current astrdata tag set, and must have the same set of input parameters.  This
is a Gemini Coding Standard, it is not enforced by the Recipe System.

\textbf{recipe} -- Represents the sequence of transformations, which are defined as
methods on a primitive class. A recipe is a simple python function recieves an
instance of the the appropriate primitive class and calls the available methods
that are to be done for a given recipe function. A \textbf{recipe} is the high-level
pipeline definition. Users can pass recipe names directly to reduce. Essentially,
a recipe is a pipeline.

\textbf{Recipe System} -- The gemin\_python framework that accommodates an arbitrary
number of defined recipes and the primitives

\textbf{reduce} -- The command line interface to the Recipe System and its associated
recipes/pipelines.

\textbf{tags} or \textbf{tag set} --  these are tags that characterise the dataset and
defined in a \code{gemini\_instruments} instrument package used to describe the
kind of observational data that has been passed to the Recipe System.,
Eg., a GMOS IMAGE; a NIRI IMAGE.
\end{quote}


\chapter{Installation}
\label{userenv:installation}\label{userenv::doc}
The \code{astrodata} package has several dependencies like \code{numpy}, \code{astropy},
and others. All dependencies of \code{gemini\_python} and \code{astrodata} are provide by
the Ureka package, and users are highly encouraged to install and use this very
useful package. It is an easy and, perhaps, best way to get everything you need
and then some. Ureka is available at \href{http://ssb.stsci.edu/ureka/}{http://ssb.stsci.edu/ureka/}.

WARNING:  The Ureka installation script will not set up IRAF for you. You need to do
that yourself. Here's how:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} cd \PYGZti{}
\PYGZdl{} mkdir iraf
\PYGZdl{} cd iraf
\PYGZdl{} mkiraf
\PYGZhy{}\PYGZhy{} creating a new uparm directory
Terminal types: xgterm,xterm,gterm,vt640,vt100,etc.
Enter terminal type: xgterm
A new LOGIN.CL file has been created in the current directory.
You may wish to review and edit this file to change the defaults.
\end{Verbatim}

Once a user has has retrieved the gemini\_python package, available as a tarfile
from the Gemini website (\href{http://gemini.edu}{http://gemini.edu}), and untarred only minor adjustments
need to be made to the user environment in order to make astrodata importable and
allow \code{reduce} to work properly.


\section{Install}
\label{userenv:config}\label{userenv:install}

\subsection{Recommended Installation}
\label{userenv:recommended-installation}
It is recommended to install the software in a location other than the standard
python location for modules (the default \code{site-packages}). This is also the
only solution if you do not have write permission to the default \code{site-packages}.
Here is how you install the software somewhere other than the default location:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} python setup.py install \PYGZhy{}\PYGZhy{}prefix=/your/favorite/location
\end{Verbatim}

\code{/your/favorite/location} must already exist.  This command will install executable
scripts in a \code{bin} subdirectory, the documentation in a \code{share} subdirectory,
and the modules in a \code{lib/python2.7/site-packages} subdirectory.  The modules being
installed are \code{astrodata}, \code{astrodata\_FITS}, \code{astrodata\_Gemini}, and \code{gempy}.
In this manual, we will only use \code{astrodata}.

Because you are not using the default location, you will need to add two paths to
your environment.  You might want to add the following to your .cshrc or
.bash\_profile, or equivalent shell configuration script.

C shell(csh, tcsh):

\begin{Verbatim}[commandchars=\\\{\}]
setenv PATH /your/favorite/location/bin:\PYGZdl{}\PYGZob{}PATH\PYGZcb{}
setenv PYTHONPATH /your/favorite/location/lib/python2.7/site\PYGZhy{}packages:\PYGZdl{}\PYGZob{}PYTHONPATH\PYGZcb{}
\end{Verbatim}

Bourne shells (sh, bash, ksh, ...)

\begin{Verbatim}[commandchars=\\\{\}]
export PATH=/your/favorite/location/bin:\PYGZdl{}\PYGZob{}PATH\PYGZcb{}
export PYTHONPATH=/your/favorite/location/lib/python2.7/site\PYGZhy{}packages:\PYGZdl{}\PYGZob{}PYTHONPATH\PYGZcb{}
\end{Verbatim}

If you added those lines to your shell configuration script, make sure your
\code{source} the file to activate the new setting.

For csh/tcsh:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} source \PYGZti{}/.cshrc
\PYGZdl{} rehash
\end{Verbatim}

For bash:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} source \PYGZti{}/.bash\PYGZus{}profile
\end{Verbatim}


\subsection{Installation under Ureka}
\label{userenv:installation-under-ureka}
Assuming that you have installed Ureka and that you have write access to the Ureka
directory, this will install \code{astrodata} in the Ureka \code{site-packages} directory.
WARNING: While easier to install and configure, this will modify your Ureka
installation.

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} python setup.py install
\end{Verbatim}

This will also add executables to the Ureka \code{bin} directory and documentation to
the Ureka \code{share} directory.

With this installation scheme, there is no need to add paths to your environment.
However, it is a lot more complicated to remove the Gemini software in case of
problems, or if you just want to clean it out after evaluation.

In tcsh, you will need to run \code{rehash} to pick the new executables written to
\code{bin}.


\section{Test the installation}
\label{userenv:test}\label{userenv:test-the-installation}
Start up the python interpreter and import astrodata:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} python
\PYGZgt{}\PYGZgt{}\PYGZgt{} import astrodata
\end{Verbatim}

Next, return to the command line and test that \code{reduce} is reachable
and runs. There may be some delay as package modules are byte compiled:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce \PYGZhy{}h
\end{Verbatim}

or

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce [\PYGZhy{}\PYGZhy{}help]
\end{Verbatim}

This will print the reduce help to the screen.

If users have Gemini fits files available, they can test that the Recipe System
is functioning as expected with a test recipe provided by the astrodata\_Gemini
package:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce \PYGZhy{}\PYGZhy{}recipe test\PYGZus{}one /path/to/gemini\PYGZus{}data.fits
\end{Verbatim}

If all is well, users will see something like:

\begin{Verbatim}[commandchars=\\\{\}]
Resetting logger for application: reduce
Logging configured for application: reduce
                       \PYGZhy{}\PYGZhy{}\PYGZhy{} reduce, v4890  \PYGZhy{}\PYGZhy{}\PYGZhy{}
              Running under astrodata Version GP\PYGZhy{}X1
All submitted files appear valid
Starting Reduction on set \PYGZsh{}1 of 1

  Processing dataset(s):
        gemini\PYGZus{}data.fits

==============================================================================
RECIPE: test\PYGZus{}one
==============================================================================
 PRIMITIVE: showParameters
 \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
 rtf = False
 suffix = \PYGZsq{}\PYGZus{}scafaasled\PYGZsq{}
 otherTest = False
 logindent = 3
 logfile = \PYGZsq{}reduce.log\PYGZsq{}
 reducecache = \PYGZsq{}.reducecache\PYGZsq{}
 storedcals = \PYGZsq{}calibrations/storedcals\PYGZsq{}
 index = 1
 retrievedcals = \PYGZsq{}calibrations/retrievedcals\PYGZsq{}
 cachedict = \PYGZob{}\PYGZsq{}storedcals\PYGZsq{}: \PYGZsq{}calibrations/storedcals\PYGZsq{}, \PYGZsq{}retrievedcals\PYGZsq{}:
              \PYGZsq{}calibrations/retrievedcals\PYGZsq{}, \PYGZsq{}calibrations\PYGZsq{}: \PYGZsq{}calibrations\PYGZsq{},
              \PYGZsq{}reducecache\PYGZsq{}: \PYGZsq{}.reducecache\PYGZsq{}\PYGZcb{}
 loglevel = \PYGZsq{}stdinfo\PYGZsq{}
 calurl\PYGZus{}dict = \PYGZob{}\PYGZsq{}CALMGR\PYGZsq{}: \PYGZsq{}http://fits/calmgr\PYGZsq{},
                \PYGZsq{}UPLOADPROCCAL\PYGZsq{}: \PYGZsq{}http://fits/upload\PYGZus{}processed\PYGZus{}cal\PYGZsq{},
                \PYGZsq{}QAMETRICURL\PYGZsq{}: \PYGZsq{}http://fits/qareport\PYGZsq{},
                \PYGZsq{}QAQUERYURL\PYGZsq{}: \PYGZsq{}http://fits/qaforgui\PYGZsq{},
                \PYGZsq{}LOCALCALMGR\PYGZsq{}: \PYGZsq{}http://localhost:\PYGZpc{}(httpport)d/calmgr/\PYGZpc{}(caltype)s\PYGZsq{}\PYGZcb{}
 logmode = \PYGZsq{}standard\PYGZsq{}
 test = True
 writeInt = False
 calibrations = \PYGZsq{}calibrations\PYGZsq{}
 .
Wrote gemini\PYGZus{}data.fits in output directory


reduce completed successfully.
\end{Verbatim}

Users curious about the URLs in the example above, i.e. \code{http://fits/...}, see
Sec. {\hyperref[discuss:fitsstore]{\emph{Fits Storage}}} in Chapter 5, Discussion.


\chapter{Interfaces}
\label{interfaces:interfaces}\label{interfaces::doc}

\section{Introduction}
\label{interfaces:introduction}
The \code{reduce} application provides a command line interface and an API, both
of which can configure and launch a Recipe System processing pipeline (a `recipe')
on the input dataset. Control of \code{reduce} and the Recipe System is provided
by a variety of options and switches. Of course, all options and switches
can be accessed and controlled through the API.


\section{Command line interface}
\label{interfaces:command-line-interface}
We begin with the command line help provided by \code{reduce -{-}help}, followed by
further description and discussion of certain non-trivial options that require
detailed explanation.

\begin{Verbatim}[commandchars=\\\{\}]
usage: reduce [\PYGZhy{}h] [\PYGZhy{}v] [\PYGZhy{}d] [\PYGZhy{}\PYGZhy{}context CONTEXT] [\PYGZhy{}\PYGZhy{}logmode LOGMODE]
            [\PYGZhy{}\PYGZhy{}logfile LOGFILE] [\PYGZhy{}\PYGZhy{}loglevel LOGLEVEL]
            [\PYGZhy{}p USERPARAM [USERPARAM ...]] [\PYGZhy{}r RECIPENAME]
            [\PYGZhy{}\PYGZhy{}user\PYGZus{}cal USER\PYGZus{}CAL] [\PYGZhy{}\PYGZhy{}suffix SUFFIX]
            fitsfile [fitsfile ...]

\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{} Gemini Observatory \PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}
\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{} Recipe Processing Management System \PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}
\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{} recipeSystem2 Release alpha (new\PYGZus{}hope) \PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}

positional arguments:
  fitsfile              fitsfile [fitsfile ...]

optional arguments:
  \PYGZhy{}h, \PYGZhy{}\PYGZhy{}help            show this help message and exit
  \PYGZhy{}v, \PYGZhy{}\PYGZhy{}version         show program\PYGZsq{}s version number and exit
  \PYGZhy{}d , \PYGZhy{}\PYGZhy{}displayflags   display all parsed option flags and exit.
  \PYGZhy{}\PYGZhy{}context CONTEXT     Use \PYGZlt{}context\PYGZgt{} for recipe selection.
  \PYGZhy{}\PYGZhy{}logmode LOGMODE     log mode: \PYGZsq{}standard\PYGZsq{}, \PYGZsq{}console\PYGZsq{}, \PYGZsq{}quiet\PYGZsq{}, \PYGZsq{}debug\PYGZsq{},\PYGZsq{}null\PYGZsq{}.
  \PYGZhy{}\PYGZhy{}logfile LOGFILE     name of log (default is \PYGZsq{}reduce.log\PYGZsq{})
  \PYGZhy{}\PYGZhy{}loglevel LOGLEVEL   Set the verbose level for console logging.
  \PYGZhy{}p USERPARAM [USERPARAM ...], \PYGZhy{}\PYGZhy{}param USERPARAM [USERPARAM ...]
                        Set a parameter from the command line.
  \PYGZhy{}r RECIPENAME, \PYGZhy{}\PYGZhy{}recipe RECIPENAME
                        Specify a recipe by name.
  \PYGZhy{}\PYGZhy{}user\PYGZus{}cal USER\PYGZus{}CAL   Specify user supplied calibrations.
  \PYGZhy{}\PYGZhy{}suffix SUFFIX       Add \PYGZsq{}suffix\PYGZsq{} to filenames at end of reduction.
\end{Verbatim}

The {[}options{]} are described in the following sections.


\subsection{Informational switches}
\label{interfaces:informational-switches}\begin{description}
\item[{\textbf{-h, --help}}] \leavevmode
show the help message and exit

\item[{\textbf{-v, --version}}] \leavevmode
show program's version number and exit

\item[{\textbf{-d, --displayflags}}] \leavevmode
Display all parsed option flags and exit.

When specified, this switch will present the user with a table of all
parsed arguments and then exit without running. This allows the user to
check that the configuration is as intended. The table provides a convenient
view of all passed and default values. Unless a user has specified a
recipe (-r, --recipe), `recipename' indicates `None' because at this point,
the Recipe System has not yet been engaged and a default recipe not yet
determined.

Eg.,:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce \PYGZhy{}d \PYGZhy{}\PYGZhy{}logmode console fitsfile.fits

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}   switches, vars, vals  \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

Literals                 var \PYGZsq{}dest\PYGZsq{}              Value
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
[\PYGZsq{}\PYGZhy{}d\PYGZsq{}, \PYGZsq{}\PYGZhy{}\PYGZhy{}displayflags\PYGZsq{}] :: displayflags         :: True
[\PYGZsq{}\PYGZhy{}p\PYGZsq{}, \PYGZsq{}\PYGZhy{}\PYGZhy{}param\PYGZsq{}]        :: userparam            :: None
[\PYGZsq{}\PYGZhy{}\PYGZhy{}logmode\PYGZsq{}]            :: logmode              :: [\PYGZsq{}console\PYGZsq{}]
[\PYGZsq{}\PYGZhy{}r\PYGZsq{}, \PYGZsq{}\PYGZhy{}\PYGZhy{}recipe\PYGZsq{}]       :: recipename           :: None
[\PYGZsq{}\PYGZhy{}\PYGZhy{}logfile\PYGZsq{}]            :: logfile              :: reduce.log
[\PYGZsq{}\PYGZhy{}\PYGZhy{}user\PYGZus{}cal\PYGZsq{}]           :: user\PYGZus{}cal             :: None
[\PYGZsq{}\PYGZhy{}\PYGZhy{}context\PYGZsq{}]            :: context              :: None
[\PYGZsq{}\PYGZhy{}\PYGZhy{}suffix\PYGZsq{}]             :: suffix               :: None
[\PYGZsq{}\PYGZhy{}\PYGZhy{}loglevel\PYGZsq{}]           :: loglevel             :: stdinfo
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

Input fits file(s):      fitsfile.fits
\end{Verbatim}

\end{description}


\subsection{Configuration Switches, Options}
\label{interfaces:configuration-switches-options}\label{interfaces:options}\begin{description}
\item[{\textbf{--context \textless{}CONTEXT\textgreater{}}}] \leavevmode
Use \textless{}CONTEXT\textgreater{} for recipe selection and for primitives sensitive to context.
Eg., \code{-{-}context QA}. When not specified, the context defaults to `QA'.

\item[{\textbf{--logmode \textless{}LOGMODE\textgreater{}}}] \leavevmode
Set logging mode. One of
\begin{itemize}
\item {} 
standard

\item {} 
console

\item {} 
quiet

\item {} 
debug

\item {} 
null

\end{itemize}

where `console' writes only to screen and `quiet' writes only to the log
file. Default is `standard'.

\item[{\textbf{--logfile \textless{}LOGFILE\textgreater{}}}] \leavevmode
Set the log file name. Default is `reduce.log' in the current directory.

\item[{\textbf{--loglevel \textless{}LOGLEVEL\textgreater{}}}] \leavevmode
Set the verbose level for console logging. One of
\begin{itemize}
\item {} 
critical

\item {} 
error

\item {} 
warning

\item {} 
status

\item {} 
stdinfo

\item {} 
fullinfo

\item {} 
debug

\end{itemize}

Default setting is `stdinfo.'

\item[{\textbf{--user\_cal \textless{}USER\_CAL {[}USER\_CAL ...{]}\textgreater{}}}] \leavevmode
The option allows users to provide their own calibrations to \code{reduce}.
Add a calibration to User Calibration Service.
`--override\_cal CAL\_PATH'
Eg.,

\code{-{-}user\_cal wcal/gsTest\_arc.fits}

\item[{\textbf{-p \textless{}USERPARAM {[}USERPARAM ...{]}\textgreater{}, --param \textless{}USERPARAM {[}USERPARAM ...{]}\textgreater{}}}] \leavevmode
Set a primitive parameter from the command line. The form `-p par=val' sets
the parameter in the reduction context such that all primitives will `see' it.
The form

\code{-p primitivename:par=val}

sets the parameter such that it applies only when the primitive is
`primitivename'. Separate parameter-value pairs by whitespace:
(eg. `-p par1=val1 par2=val2')

See Sec. {\hyperref[interfaces:userpars]{\emph{Overriding Primitive Parameters}}}, for more information on these values.

\item[{\textbf{-r \textless{}RECIPENAME\textgreater{}, --recipe \textless{}RECIPENAME\textgreater{}}}] \leavevmode
Specify an explicit recipe to be used rather than internally determined by
a dataset's \textless{}ASTROTYPE\textgreater{}. Default is None and later determined by the Recipe
System based on the AstroDataType.

\item[{\textbf{--suffix \textless{}SUFFIX\textgreater{}}}] \leavevmode
Add `suffix' to output filenames at end of reduction.

\end{description}


\subsection{Nominal Usage}
\label{interfaces:nominal-usage}
The minimal call for reduce can be

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce \PYGZlt{}dataset.fits\PYGZgt{}
\end{Verbatim}

While this minimal call is available at the Gemini Observatory (see Sec.
{\hyperref[discuss:fitsstore]{\emph{Fits Storage}}}), if a calibration service is unavailable to the user --
likely true for most users -- users should call \code{reduce} on a specified
dataset by providing calibration files with the  --user\_cal option.

For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce \PYGZhy{}\PYGZhy{}user\PYGZus{}cal FOO\PYGZus{}bias.fits \PYGZlt{}dataset.fits\PYGZgt{}
\end{Verbatim}

Such a command for complex processing of data is possible because AstroData
and the Recipe System do all the necessary work in determining how the data are to
be processed, which is critcially based upon the determination of the \emph{tag set}
that applies to that data.

Without any user-specified recipe (-r --recipe), the default recipe is
\code{qaReduce}, which is defined for various AstroData tag sets and currently used
during summit operations. Unless passed a explicit recipe (-r --recipename),
the Recipe System uses the astrodata tag set and context to locate the appropriate
recipe to run.

The recipe libraries for a GMOS\_IMAGE, are defined under

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{GMOS}\PYG{o}{.}\PYG{n}{recipes}\PYG{o}{.}\PYG{n}{QA}
\end{Verbatim}

and the recipe system will search available recipe libraries for a match. Naming
of recipe library module(s) is arbitrary. If all defaults are picked up, this
results in the \code{qaReduce} recipe function being selected and which specifies
that the following primitives are called on the data

\begin{Verbatim}[commandchars=\\\{\}]
def qaReduce(p):
    p.prepare()
    p.addDQ()
    p.addVAR(read\PYGZus{}noise=True)
    p.detectSources()
    p.measureIQ(display=True))
    p.measureBG()
    p.measureCCAndAstrometry()
    p.overscanCorrect()
    p.biasCorrect()
    p.ADUToElectrons()
    p.addVAR(poisson\PYGZus{}noise=True)
    p.flatCorrect()
    p.mosaicDetectors()
    p.makeFringe()
    p.fringeCorrect()
    p.detectSources()
    p.measureIQ(display=True))
    p.measureBG()
    p.measureCCAndAstrometry()
    p.addToList(purpose=forStack)
\end{Verbatim}

The point here is not to overwhelm readers with a stack of primitive names, but
to present both the default pipeline processing that the above simple \code{reduce}
command invokes and to demonstrate how much the \code{reduce} interface abstracts
away the complexity of the processing that is engaged with the simplicity of
commands.


\subsection{Overriding Primitive Parameters}
\label{interfaces:userpars}\label{interfaces:overriding-primitive-parameters}
In some cases, users may wish to change the functional behaviour of certain
processing steps, i.e. change default behaviour of primitive
functions.

Each primitive has a set of pre-defined parameters, which are used to control
functional behaviour of the primitive. Each defined parameter has a ``user
override'' token, which indicates that a particular parameter may be overridden
by the user. Users can adjust parameter values from the reduce command line with
the option,
\begin{quote}

\textbf{-p, --param}
\end{quote}

If permitted by the ``user override'' token, parameters and values specified
through the \textbf{-p, --param} option will \emph{override} the defined
parameter default value and may alter default behaviour of the primitive
accessing this parameter. A user may pass several parameter-value pairs with
this option.

Eg.:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce \PYGZhy{}p par1=val1 par2=val2 [par3=val3 ... ] \PYGZlt{}fitsfile1.fits\PYGZgt{}
\end{Verbatim}

User-specified parameter values can be focused on one primitive. For example,
if a parameter applies to more than one primitive, for example, the parameter,
\code{threshold}, the user can explicitly direct a new parameter value to a
particular primitive. The `detection threshold' has a defined default, but a
user may alter this parameter default to change the source detection behaviour:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce \PYGZhy{}p detectSources:threshold=4.5 \PYGZlt{}fitsfile.fits\PYGZgt{}
\end{Verbatim}


\subsection{The @file facility}
\label{interfaces:the-file-facility}\label{interfaces:atfile}
The reduce command line interface supports what might be called an `at-file'
facility (users and readers familiar with IRAF will recognize this facility).
This facility allows users to provide any and all command line options and flags
to \code{reduce} via in a single acsii text file.

By passing an @file to \code{reduce} on the command line, users can encapsulate all
the options and positional arguments they might wish to specify in a single
@file. It is possible to use multiple @files and even to embed one or more
@files in another. The parser opens all files sequentially and parses
all arguments in the same manner as if they were specified on the command line.
Essentially, an @file is some or all of the command line and parsed identically.

To illustrate the convenience provided by an \href{mailto:'@file}{`@file}`, let us begin with an
example \emph{reduce} command line that has a number of arguments:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce \PYGZhy{}p detectSources:threshold=4.5 tpar=100 \PYGZhy{}r recipe.ArgsTest \PYGZhy{}\PYGZhy{}context SQ
  S20130616S0019.fits N20100311S0090.fits
\end{Verbatim}

Ungainly, to be sure. Here, two (2) \emph{user parameters} are being specified
with \textbf{-p}, a \emph{recipe} with \textbf{-r}, and a \emph{context} argument is specified
to be \textbf{qa} . This can be wrapped in a plain text @file called
\emph{reduce\_args.par}:

\begin{Verbatim}[commandchars=\\\{\}]
S20130616S0019.fits
N20100311S0090.fits
\PYGZhy{}\PYGZhy{}param
tpar=100
detectSources:threshold=4.5
\PYGZhy{}r recipe.ArgsTests
\PYGZhy{}\PYGZhy{}context sq
\end{Verbatim}

This then turns the previous reduce command line into something a little more
\emph{keyboard friendly}:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce @reduce\PYGZus{}args.par
\end{Verbatim}

The order of these arguments is irrelevant. The above file could be thus written
like:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZhy{}r recipe.ArgsTests
\PYGZhy{}\PYGZhy{}param
tpar=100
detectSources:threshold=4.5
\PYGZhy{}\PYGZhy{}context qa
S20130616S0019.fits
N20100311S0090.fits
\end{Verbatim}

Comments are accommodated, both as full line and in-line with the \code{\#}
character.  White space is the only significant separator of arguments: spaces,
tabs, newlines are all equivalent when argument parsing.  This means
the user can ``arrange'' their @file for clarity.

Here's a more readable version of the file from the previous example
using comments and tabulation:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZsh{} reduce parameter file
\PYGZsh{} GDPSG

\PYGZsh{} Spec the recipe
\PYGZhy{}r
    recipe.ArgsTests  \PYGZsh{} test recipe

\PYGZsh{} primitive parameters here
\PYGZhy{}\PYGZhy{}param
    tpar=100
    detectSources:threshold=4.5

\PYGZhy{}\PYGZhy{}context
    qa                \PYGZsh{} QA context

S20130616S0019.fits
N20100311S0090.fits
\end{Verbatim}

All the above  examples of \code{reduce\_args.par} are equivalently parsed, which
users may check by adding the \textbf{-d} flag:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce \PYGZhy{}d @redpars.par

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}   switches, vars, vals  \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

Literals                   var \PYGZsq{}dest\PYGZsq{}         Value
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
[\PYGZsq{}\PYGZhy{}\PYGZhy{}invoked\PYGZsq{}]              :: invoked         :: False
[\PYGZsq{}\PYGZhy{}d\PYGZsq{}, \PYGZsq{}\PYGZhy{}\PYGZhy{}displayflags\PYGZsq{}]   :: displayflags    :: True
[\PYGZsq{}\PYGZhy{}p\PYGZsq{}, \PYGZsq{}\PYGZhy{}\PYGZhy{}param\PYGZsq{}]          :: userparam       :: [\PYGZsq{}tpar=100\PYGZsq{}, \PYGZsq{}detectSources:threshold=4.5\PYGZsq{}]
[\PYGZsq{}\PYGZhy{}\PYGZhy{}logmode\PYGZsq{}]              :: logmode         :: standard
[\PYGZsq{}\PYGZhy{}r\PYGZsq{}, \PYGZsq{}\PYGZhy{}\PYGZhy{}recipe\PYGZsq{}]         :: recipename      :: [\PYGZsq{}recipe.ArgTests\PYGZsq{}]
[\PYGZsq{}\PYGZhy{}\PYGZhy{}logfile\PYGZsq{}]              :: logfile         :: reduce.log
[\PYGZsq{}\PYGZhy{}\PYGZhy{}user\PYGZus{}cal\PYGZsq{}]             :: user\PYGZus{}cals       :: None
[\PYGZsq{}\PYGZhy{}\PYGZhy{}context\PYGZsq{}]              :: context         :: [\PYGZsq{}QA\PYGZsq{}]
[\PYGZsq{}\PYGZhy{}\PYGZhy{}calmgr\PYGZsq{}]               :: cal\PYGZus{}mgr         :: None
[\PYGZsq{}\PYGZhy{}\PYGZhy{}suffix\PYGZsq{}]               :: suffix          :: None
[\PYGZsq{}\PYGZhy{}\PYGZhy{}loglevel\PYGZsq{}]             :: loglevel        :: stdinfo
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

Input fits file(s):   S20130616S0019.fits
Input fits file(s):   N20100311S0090.fits
\end{Verbatim}


\subsection{Recursive @file processing}
\label{interfaces:recursive-file-processing}
As implemented, the @file facility will recursively handle, and process
correctly, other @file specifications that appear in a passed @file or
on the command line. For example, we may have another file containing a
list of fits files, separating the command line flags from the positional
arguments.

We have a plain text `fitsfiles' containing the line:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{test\PYGZus{}data}\PYG{o}{/}\PYG{n}{S20130616S0019}\PYG{o}{.}\PYG{n}{fits}
\end{Verbatim}

We can indicate that this file is to be consumed with the prefix character
``@'' as well. In this case, the `reduce\_args.par' file could thus appear:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZsh{} reduce test parameter file

@fitsfiles       \PYGZsh{} file with fits files

\PYGZsh{} primitive parameters.
\PYGZhy{}\PYGZhy{}param
    detectSources:threshold=4.5
    tpar=99
    FOO=BAR

\PYGZsh{} Spec the recipe
\PYGZhy{}r recipe.ArgTests
\end{Verbatim}

The parser will open and read the @fitsfiles, consuming those lines in the
same way as any other command line arguments. Indeed, such a file need not only
contain fits files (positional arguments), but other arguments as well. This is
recursive. That is, the @fitsfiles can contain other at-files'', which can contain
other ``at-files'', which can contain ..., etc. These will be processed
serially.

As stipulated earlier, because the @file facility provides arguments equivalent
to those that appear on the command line, employment of this facility means that
a reduce command line could assume the form:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce @parfile @fitsfiles
\end{Verbatim}

or equally:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce @fitsfiles @parfile
\end{Verbatim}

where `parfile' could contain the flags and user parameters, and `fitsfiles'
could contain a list of datasets.

Eg., fitsfiles comprises the one line:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{test\PYGZus{}data}\PYG{o}{/}\PYG{n}{N20100311S0090}\PYG{o}{.}\PYG{n}{fits}
\end{Verbatim}

while parfile holds all other specifications:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZsh{} reduce test parameter file
\PYGZsh{} GDPSG

\PYGZsh{} primitive parameters.
\PYGZhy{}\PYGZhy{}param
    detectSources:threshold=4.5
    tpar=99            \PYGZsh{} This is a test parameter
    FOO=BAR            \PYGZsh{} This is a test parameter

\PYGZsh{} Spec the recipe
\PYGZhy{}r recipe.ArgTests
\end{Verbatim}

The @file does not need to be located in the current directory.  Normal,
directory path syntax applies, for example:

\begin{Verbatim}[commandchars=\\\{\}]
reduce @../../mydefaultparams @fitsfile
\end{Verbatim}


\subsection{Overriding @file values}
\label{interfaces:overriding-file-values}
The \code{reduce} application employs a customized command line parser such that
the command line option

\textbf{-p} or \textbf{--param}

will accumulate a set of parameters \emph{or} override a particular parameter.
This may be seen when a parameter is specified in a user @file and then
specified on the command line. For unitary value arguments, the command line
value will \emph{override} the @file value.

It is further specified that if one or more datasets (i.e. positional arguments)
are passed on the command line, \emph{all fits files appearing as positional arguments}
\emph{in the parameter file will be replaced by the command line arguments.}

Using the parfile above,

Eg. 1)  Accumulate a new parameter:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce @parfile \PYGZhy{}\PYGZhy{}param FOO=BARSOOM

parsed options:
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
FITS files:    [\PYGZsq{}S20130616S0019.fits\PYGZsq{}, \PYGZsq{}N20100311S0090.fits\PYGZsq{}]
Parameters:    tpar=100, detectSources:threshold=4.5, FOO=BARSOOM
RECIPE:        recipe.ArgsTest
\end{Verbatim}

Eg. 2) Override a parameter in the @file:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce @parfile \PYGZhy{}\PYGZhy{}param tpar=99

parsed options:
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
FITS files:    [\PYGZsq{}S20130616S0019.fits\PYGZsq{}, \PYGZsq{}N20100311S0090.fits\PYGZsq{}]
Parameters:    tpar=99, detectSources:threshold=4.5
RECIPE:        recipe.ArgsTest
\end{Verbatim}

Eg. 3) Override the recipe:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce @parfile \PYGZhy{}r=recipe.FOO

parsed options:
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
FITS files:    [\PYGZsq{}S20130616S0019.fits\PYGZsq{}, \PYGZsq{}N20100311S0090.fits\PYGZsq{}]
Parameters:    tpar=100, detectSources:threshold=4.5
RECIPE:        recipe.FOO
\end{Verbatim}

Eg. 4) Override a recipe and specify another fits file. The file names in
the @file will be ignored:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce @parfile \PYGZhy{}r=recipe.FOO test\PYGZus{}data/N20100311S0090\PYGZus{}1.fits

parsed options:
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
FITS files:    [\PYGZsq{}test\PYGZus{}data/N20100311S0090\PYGZus{}1.fits\PYGZsq{}]
Parameters:    tpar=100, detectSources:threshold=4.5
RECIPE:        recipe.FOO
\end{Verbatim}


\section{Application Programming Interface (API)}
\label{interfaces:application-programming-interface-api}
\begin{notice}{note}{Note:}
This section describes and discusses the programmatic interface
available on the class Reduce.  This section is for advanced
users wishing to code using the \code{Reduce} class, rather than using
\code{reduce} at the command line.
\end{notice}

The \code{reduce} application is essentially a skeleton script providing the
described command line interface. After parsing the command line, the script
then passes the parsed arguments to its main() function, which in turn calls
the Reduce() class constructor with ``args''. The Reduce class is scriptable by
any user as the following discussion illustrates.


\subsection{Class Reduce, logging, and the runr() method}
\label{interfaces:class-reduce-logging-and-the-runr-method}
The Reduce class is defined under the \code{gemini\_python} code base in the
\code{recipe\_system.reduction} module, \code{coreReduce.py}.

The Reduce() class is importable and provides settable attributes and a callable
that can be used programmatically. Callers need not supply an ``args'' parameter
to the class initializer, i.e. \_\_init\_\_(). An instance of Reduce will have all
the same arguments as in a command line scenario, available as attributes on the
instance. Once an instance of Reduce() is instantiated and instance attributes
set as needed, there is one (1) method to call, \textbf{runr()}. This is the only
public method on the class.

Eg.,

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{recipe\PYGZus{}system.reduction.coreReduce} \PYG{k+kn}{import} \PYG{n}{Reduce}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce} \PYG{o}{=} \PYG{n}{Reduce}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{files}
\PYG{g+go}{[]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{files}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{S20130616S0019.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{files}
\PYG{g+go}{[\PYGZsq{}S20130616S0019.fits\PYGZsq{}]}
\end{Verbatim}

Or callers may simply set the \code{files} attribute to be an existing list of files

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{fits\PYGZus{}list} \PYG{o}{=} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{FOO.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{BAR.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{files} \PYG{o}{=} \PYG{n}{fits\PYGZus{}list}
\end{Verbatim}

On the command line, users may specify a recipe with the \code{-r} {[} \code{-{-}recipe} {]}
flag. Programmatically, users directly set the recipe:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{recipename} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{recipe.MyRecipe}\PYG{l+s}{\PYGZsq{}}
\end{Verbatim}

All other properties and  attributes on the API may be set in standard pythonic
ways. See Appendix
{\hyperref[appendices/reduce_properties:props]{\emph{Class Reduce: Settable properties and attributes}}} for further
discussion and more examples.


\subsubsection{Using the logger}
\label{interfaces:using-the-logger}
\begin{notice}{note}{Note:}
When using an instance of Reduce() directly, callers must configure
their own logger. Reduce() does not configure logutils prior to using
a logger as returned by logutils.get\_logger(). The following discussion
demonstrates how this is easily done. It is \emph{highly recommended}
that callers configure the logger.
\end{notice}

It is recommended that callers of Reduce use a logger supplied by the astrodata
module \code{logutils}. This module employs the python logger module, but with
recipe system specific features and embellishments. The recipe system
expects to have access to a logutils logger object, which callers should provide
prior to calling the \code{runr()} method.

To use \code{logutils}, import, configure, and get it:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{gempy.utils} \PYG{k+kn}{import} \PYG{n}{logutils}
\PYG{n}{logutils}\PYG{o}{.}\PYG{n}{config}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{log} \PYG{o}{=} \PYG{n}{logutils}\PYG{o}{.}\PYG{n}{get\PYGZus{}logger}\PYG{p}{(}\PYG{n}{\PYGZus{}\PYGZus{}name\PYGZus{}\PYGZus{}}\PYG{p}{)}
\end{Verbatim}

where \code{\_\_name\_\_} is usually the calling module's \_\_name\_\_ property, but can
be any string value. Once configured and instantiated, the \code{log} object is
ready to use. See section {\hyperref[interfaces:options]{\emph{Configuration Switches, Options}}} for logging levels described on the
\code{-{-}loglevel} option.

Once an instance of Reduce has been made, callers may (should) configure the
logutils facility with attributes available on the instance. Instances of
\code{Reduce()} provide the following logger parameters as attributes on the
instance with appropriate default values:
\begin{itemize}\setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}
\item {} 
logfile

\item {} 
loglevel

\item {} 
logmode

\item {} 
logindent

\end{itemize}

The \code{reduce} command line provides access to the first three of these
attributes, as described in Sec. {\hyperref[interfaces:options]{\emph{Configuration Switches, Options}}}, but \code{logindent}, which
controls the indention levels of logging output, is accessible only through the
public interface on an instance of \code{Reduce()}. It is not anticipated that users
will need, or even want, to change the value of \code{logindent}, but it is possible.

An instance of \code{Reduce()} provides the following attributes that may be passed
to the \code{logutils.config()}. The default values provided for these logging
configuration parameters may be examined through direct inspection:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce} \PYG{o}{=} \PYG{n}{Reduce}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logfile}
\PYG{g+go}{\PYGZsq{}reduce.log\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logmode}
\PYG{g+go}{\PYGZsq{}standard\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{loglevel}
\PYG{g+go}{\PYGZsq{}stdinfo\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logindent}
\PYG{g+go}{3}
\end{Verbatim}

Users may adjust these values and then pass them to the \code{logutils.config()}
function, or pass other values directly to \code{config()}. This is precisely what
\code{reduce} does when it configures logutils. See Sec. {\hyperref[interfaces:options]{\emph{Configuration Switches, Options}}}  and
Appendix {\hyperref[appendices/reduce_properties:props]{\emph{Class Reduce: Settable properties and attributes}}} for
allowable and default values of these and other options.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{gempy.utils} \PYG{k+kn}{import} \PYG{n}{logutils}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{logutils}\PYG{o}{.}\PYG{n}{config}\PYG{p}{(}\PYG{n}{file\PYGZus{}name}\PYG{o}{=}\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logfile}\PYG{p}{,} \PYG{n}{mode}\PYG{o}{=}\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logmode}\PYG{p}{,}
\PYG{g+go}{                    console\PYGZus{}lvl=reduce.loglevel)}
\end{Verbatim}

\begin{notice}{note}{Note:}
logutils.config() may be called mutliply, should callers, for example,
want to change logfile names for different calls on runr().
\end{notice}


\subsubsection{Call the runr() method}
\label{interfaces:call-the-runr-method}
Once a user is satisfied that all attributes are set to the desired values, and
the logger is configured, the runr() method on the ``reduce'' instance may then be
called. The following brings the examples above into one ``end-to-end'' use of
Reduce and logutils:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{recipe\PYGZus{}system.reduction.coreReduce} \PYG{k+kn}{import} \PYG{n}{Reduce}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{gempy.utils} \PYG{k+kn}{import} \PYG{n}{logutils}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce} \PYG{o}{=} \PYG{n}{Reduce}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{files}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{S20130616S0019.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{recipename} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{recipe.MyRecipe}\PYG{l+s}{\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logfile} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{my\PYGZus{}reduce\PYGZus{}run.log}\PYG{l+s}{\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{logutils}\PYG{o}{.}\PYG{n}{config}\PYG{p}{(}\PYG{n}{file\PYGZus{}name}\PYG{o}{=}\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logfile}\PYG{p}{,} \PYG{n}{mode}\PYG{o}{=}\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logmode}\PYG{p}{,}
\PYG{g+go}{                    console\PYGZus{}lvl=reduce.loglevel)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{runr}\PYG{p}{(}\PYG{p}{)}
\PYG{g+go}{All submitted files appear valid}
\PYG{g+go}{Starting Reduction on set \PYGZsh{}1 of 1}
\PYG{g+go}{Processing dataset(s):}
\PYG{g+go}{S20130616S0019.fits}
\PYG{g+gp}{...}
\end{Verbatim}

Processing will then proceed in the usual manner. Astute readers will note that
callers need not create more than one Reduce instance in order to call runr()
with a different dataset or options.

Eg.,:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{recipe\PYGZus{}system.reduction.coreReduce} \PYG{k+kn}{import} \PYG{n}{Reduce}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{gempy.utils} \PYG{k+kn}{import} \PYG{n}{logutils}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce} \PYG{o}{=} \PYG{n}{Reduce}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{files}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{S20130616S0019.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{recipename} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{recipe.MyRecipe}\PYG{l+s}{\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logfile} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{my\PYGZus{}reduce\PYGZus{}run.log}\PYG{l+s}{\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{logutils}\PYG{o}{.}\PYG{n}{config}\PYG{p}{(}\PYG{n}{file\PYGZus{}name}\PYG{o}{=}\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logfile}\PYG{p}{,} \PYG{n}{mode}\PYG{o}{=}\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logmode}\PYG{p}{,}
\PYG{g+go}{                     console\PYGZus{}lvl=reduce.loglevel)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{runr}\PYG{p}{(}\PYG{p}{)}
\PYG{g+go}{  ...}
\PYG{g+go}{reduce completed successfully.}

\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{recipename} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{recipe.NewRecipe}\PYG{l+s}{\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{files} \PYG{o}{=} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{newfile.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{userparam} \PYG{o}{=} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{clobber=True}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{runr}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

Once an attribute is set on an instance, such as above with \code{userparam}, it is
always set on the instance. If, on another call of runr() the caller does not
wish to have \code{clobber=True}, simply reset the property:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{userparam} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{runr}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

Readers may wish to examine the examples in Appendix
{\hyperref[appendices/reduce_properties:props]{\emph{Class Reduce: Settable properties and attributes}}}


\chapter{Supplemental tools}
\label{supptools:supplemental-tools}\label{supptools::doc}
The astrodata package provides a number of command line driven tools, which
users may find helpful in executing reduce on their data.

With the installation and configuration of \code{astrodata} and \code{reduce} comes
some supplemental tools to help users discover information, not only about their
own data, but about the Recipe System, such as available recipes, primitives,
and defined AstroDataTypes.

If the user environment has been configured correctly these applications
will work directly.


\section{typewalk}
\label{supptools:typewalk}\label{supptools:id1}
\code{typewalk} examines files in a directory or directory tree and reports the types
and status values through the AstroDataType classification scheme. Running \code{typewalk}
on a directory containing some Gemini datasets will demonstrate what users can expect
to see. If a user has downloaded gemini\_python package with the `test\_data', the
user can move to this directory and run \code{typewalk} on that extensive set of
Gemini datasets.

By default, \code{typewalk} will recurse all subdirectories under the current
directory. Users may specify an explicit directory with the \textbf{-d} or
\textbf{--dir} option; the behavior remains recursive.

\code{typewalk} provides the following options {[}\textbf{-h, --help}{]}:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZhy{}h, \PYGZhy{}\PYGZhy{}help            show this help message and exit
\PYGZhy{}b BATCHNUM, \PYGZhy{}\PYGZhy{}batch BATCHNUM
                      In shallow walk mode, number of files to process at a
                      time in the current directory. Controls behavior in
                      large data directories. Default = 100.
\PYGZhy{}d TWDIR, \PYGZhy{}\PYGZhy{}dir TWDIR
                      Walk this directory and report types. default is cwd.
\PYGZhy{}f FILEMASK, \PYGZhy{}\PYGZhy{}filemask FILEMASK
                      Show files matching regex \PYGZlt{}FILEMASK\PYGZgt{}. Default is all
                      .fits and .FITS files.
\PYGZhy{}n, \PYGZhy{}\PYGZhy{}norecurse       Do not recurse subdirectories.
\PYGZhy{}\PYGZhy{}or                  Use OR logic on \PYGZsq{}types\PYGZsq{} criteria. If not specified,
                      matching logic is AND (See \PYGZhy{}\PYGZhy{}types). Eg., \PYGZhy{}\PYGZhy{}or \PYGZhy{}\PYGZhy{}types
                      SOUTH GMOS IMAGE will report datasets that are one of
                      SOUTH *OR* GMOS *OR* IMAGE.
\PYGZhy{}o OUTFILE, \PYGZhy{}\PYGZhy{}out OUTFILE
                      Write reported files to this file. Effective only with
                      \PYGZhy{}\PYGZhy{}tags option.
\PYGZhy{}\PYGZhy{}tags TAGS [TAGS ...]
                      Find datasets that match only these tag criteria. Eg.,
                      \PYGZhy{}\PYGZhy{}tags SOUTH GMOS IMAGE will report datasets that are
                      all tagged SOUTH *and* GMOS *and* IMAGE.
\PYGZhy{}\PYGZhy{}xtags XTAGS [XTAGS ...]
                      Exclude \PYGZlt{}xtags\PYGZgt{} from reporting.
\end{Verbatim}

Files are selected and reported through a regular expression mask which,
by default, finds all ''.fits'' and ''.FITS'' files. Users can change this mask
with the \textbf{-f, --filemask} option.

As the \textbf{--types} option indicates, \code{typewalk} can find and report data that
match specific type criteria. For example, a user might want to find all GMOS
image flats under a certain directory. \code{typewalk} will locate and report all
datasets that would match the AstroDataType, GMOS\_IMAGE\_FLAT.

A user may request that a file be written containing all datasets
matching AstroDataType qualifiers passed by the \textbf{--types} option. An output
file is specified through the \textbf{-o, --out} option. Output files are formatted
so they may be passed \emph{directly to the reduce command line} via that applications
`at-file' (@file) facility. See {\hyperref[interfaces:atfile]{\emph{The @file facility}}} or the reduce help for more on
`at-files'.

Users may select type matching logic with the \textbf{--or} switch. By default,
qualifying logic is AND, i.e. the logic specifies that \emph{all} types must be
present (x AND y); \textbf{--or} specifies that ANY types, enumerated with
\textbf{--types}, may be present (x OR y). \textbf{--or} is only effective when the
\textbf{--types} option is specified with more than one type.

For example, find all GMOS images from Cerro Pachon in the top level
directory and write out the matching files, then run reduce on them
(\textbf{-n} is `norecurse'):

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} typewalk \PYGZhy{}n \PYGZhy{}\PYGZhy{}tags SOUTH GMOS IMAGE \PYGZhy{}\PYGZhy{}out gmos\PYGZus{}images\PYGZus{}south
\PYGZdl{} reduce @gmos\PYGZus{}images\PYGZus{}south
\end{Verbatim}

Find all F2 SPECT datasets in a directory tree:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} typewalk \PYGZhy{}\PYGZhy{}tags SPECT F2
\end{Verbatim}

This will also report match results to stdout, colourized if requested (\textbf{-c}).

Users may find the \textbf{--xtypes} flag useful, as it provides a facility for
filtering results further by allowing certain types to be excluded from the
report.

For example, find GMOS\_IMAGE types, but exclude ACQUISITION images from reporting:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} typewalk \PYGZhy{}\PYGZhy{}tags GMOS IMAGE \PYGZhy{}\PYGZhy{}xtags ACQUISITION

directory: ../test\PYGZus{}data/output
   S20131010S0105.fits ............... (GEMINI) (SOUTH) (GMOS) (IMAGE) (RAW)
   (SIDEREAL) (UNPREPARED)

   S20131010S0105\PYGZus{}forFringe.fits ..... (GEMINI) (SOUTH) (GMOS)
   (IMAGE) (NEEDSFLUXCAL) (OVERSCAN\PYGZus{}SUBTRACTED) (OVERSCAN\PYGZus{}TRIMMED)
   (PREPARED) (PROCESSED\PYGZus{}SCIENCE) (SIDEREAL)

   S20131010S0105\PYGZus{}forStack.fits ...... (GEMINI) (SOUTH) (GMOS) (IMAGE)
   (NEEDSFLUXCAL) (OVERSCAN\PYGZus{}SUBTRACTED) (OVERSCAN\PYGZus{}TRIMMED)
   (PREPARED) (SIDEREAL)
\end{Verbatim}

Exclude GMOS ACQUISITION images and GMOS IMAGE datasets that have been
`prepared':

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} typewalk \PYGZhy{}\PYGZhy{}tags GMOS IMAGE \PYGZhy{}\PYGZhy{}xtags ACQUISITION PREPARED

directory: ../test\PYGZus{}data/output
   S20131010S0105.fits ............... (GEMINI) (SOUTH) (GMOS) (IMAGE) (RAW)
   (SIDEREAL) (UNPREPARED)
\end{Verbatim}

With \textbf{--tags} and \textbf{--xtags}, users may really tune their searches for very
specific datasets.


\chapter{Discussion}
\label{discuss:discussion}\label{discuss::doc}

\section{Fits Storage}
\label{discuss:fits-storage}\label{discuss:fitsstore}
The URLs that appear in \code{test\_one} recipe example (Sec. {\hyperref[userenv:test]{\emph{Test the installation}}}), reference
web services available within the Gemini Observatory's operational environment.
They will \emph{not} be available directly to users running \code{reduce} outside of the
Gemini Observatory environment.

In the context of \code{reduce} and the Astrodata Recipe System, FitsStorage provides
a calibration management and association feature. Essentially, given a science
frame (or any frame that requires calibration) and a calibration
type requested, FitsStorage is able to automatically choose the best available
calibration of the required type to apply to the science frame. The Recipe System
uses a machine-oriented calibration manager interface in order to select
calibration frames to apply as part of pipeline processing.

Though this service is not currently available to general gemini\_python users,
plans to provide this as a local calibration service are in place and expected
for {\hyperref[discuss:future]{\emph{Future Enhancements}}}.


\section{Future Enhancements}
\label{discuss:future}\label{discuss:future-enhancements}

\subsection{Intelligence}
\label{discuss:intelligence}
One enhancement long imagined is what has been generally termed `intelligence'.
That is, an ability for either \code{reduce} or some utility to automatically do
AstroDataType classification of a set of data, group them appropriately, and
then pass these grouped data to the Recipe System.

As things stand now, it is up to the user to pass commonly typed data to
\code{reduce}. As shown in the previous section, {\hyperref[supptools:typewalk]{\emph{typewalk}}}, \code{typewalk}
can help a user perform this task and create a `ready-to-run' @file that can
be passed directly to \code{reduce}. Properly implemented `intelligence' will
\emph{not} require the user to determine the AstroDataTypes of datasets.


\subsection{Local Calibration Service}
\label{discuss:local-calibration-service}
The Fits Storage service will be delivered as part of a future release and will
provide the calibration management and association features of {\hyperref[discuss:fitsstore]{\emph{Fits Storage}}}:
for use with the public release of the \emph{gemini\_python} data reduction package.
This feature will provide automatic calibration selection for both pipeline
(recipe) operations and in an interactive processing environment.


\chapter{6. Acknowledgments}
\label{ack::doc}\label{ack:acknowledgments}
The Gemini Observatory is operated by the Association of Universities for
Research in Astronomy (AURA), Inc., under a cooperative agreement with the NSF on
behalf of the Gemini partnership: the National Science Foundation
(United States), the Science and Technology Facilities Council (United Kingdom),
the National Research Council (Canada), CONICYT (Chile), the Australian
Research Council (Australia), Ministerio da Ciencia e Tecnologia (Brazil),
and Ministerio de Ciencia, Tecnologia e Innovacion Productiva (Argentina).
% Set up the appendix mode and modify the LaTeX toc behavior
\appendix
\noappendicestocpagenum
\addappheadtotoc

\chapter{\emph{reduce} demo}
\label{appendices/appendix_demo::doc}\label{appendices/appendix_demo:reduce-demo}
Original demo author: Kathleen Labrie, October 2014


\section{Setting up}
\label{appendices/appendix_demo:setting-up}
First install Ureka, which can be obtained at \href{http://ssb.stsci.edu/ureka/}{http://ssb.stsci.edu/ureka/}.

The second step is to install \code{gemini\_python} as described in
{\hyperref[userenv:config]{\emph{Section 2 - Installation}}}.
Please do make sure that the command \emph{reduce} is in your \code{PATH} and that
\code{PYTHONPATH} includes the location where the modules \code{astrodata}, the
\code{recipe\_system}, and \code{gempy} are installed.

The demo data is distributed separately.  You can find the demo data package
\code{gemini\_python\_datapkg-X1.tar.gz} on the Gemini website where you found the
gemini\_python package.  Unpack the data package somewhere convenient:

\begin{Verbatim}[commandchars=\\\{\}]
tar xvzf gemini\PYGZus{}python\PYGZus{}datapkg\PYGZhy{}X1.tar.gz
\end{Verbatim}

In there, you will find a subdirectory named \code{data\_for\_reduce\_demo}.  Those are
the data we will use here.  You will also find an empty directory called
\code{playground}.  This is your playground. The instructions in this demo assume that
you are running the \code{reduce} command from that directory.  There is no requirements
to run \code{reduce} from that directory, but if you want to follow the demo to the
letter, this is where you should be for all the paths to work.


\section{Introduction to the Demo}
\label{appendices/appendix_demo:introduction-to-the-demo}
In this demo, we will reduce a simple dither-on-source GMOS imaging sequence.
We will first process the raw biases, and then the raw twilight flats.  We will
then use those processed files to process and stack the science observation.

Instead of the default Quality Assessment (QA) recipe that is used at the Gemini
summits, we will use another recipe that will focus on the reduction rather
than on the multiple measurements of the QA metrics used at night.  QA metrics,
here the image quality (IQ), will only be measured at the end of the reduction
rather than throughout the reduction.   Another difference between the standard
QA recipe and the demo recipe, is that the demo recipe does stack the data, while
the stacking is turned off in the QA context.

The demo recipe is essentially a Quick Look recipe.  It is NOT valid for Science
Quality.  Remember that what you are using is a QA pipeline, not a Science pipeline.


\section{The Recipes}
\label{appendices/appendix_demo:the-recipes}
To process the biases and the flats we will be using the standard recipes. The
system will be able to pick those automatically when it recognizes the input data
as GMOS biases and GMOS twilight flats.

For the science data, we will override the recipe selection to use the Demo recipe.
If we were not to override the recipe selection, the system would automatically
select the QA recipe.  The Demo recipe is more representative of a standard
Quick-Look reduction with stacking, hence probably more interesting to the reader.

The standard recipe to process GMOS biases is named \code{makeProcessedBias}
and contains the instruction set:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c}{\PYGZsh{} This recipe performs the standardization and corrections needed to convert}
\PYG{c}{\PYGZsh{} the raw input bias images into a single stacked bias image. This output}
\PYG{c}{\PYGZsh{} processed bias is stored on disk using storeProcessedBias and has a name}
\PYG{c}{\PYGZsh{} equal to the name of the first input bias image with \PYGZdq{}\PYGZus{}bias.fits\PYGZdq{} appended.}

\PYG{n}{p}\PYG{o}{.}\PYG{n}{prepare}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{addDQ}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{addVAR}\PYG{p}{(}\PYG{n}{read\PYGZus{}noise}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{overscanCorrect}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{addToList}\PYG{p}{(}\PYG{n}{purpose}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{forStack}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{getList}\PYG{p}{(}\PYG{n}{purpose}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{forStack}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{stackFrames}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{storeProcessedBias}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

The standard recipe to process GMOS twilight flats is named
\code{makeProcessedFlat} and contains the instruction set:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c}{\PYGZsh{} This recipe performs the standardization and corrections needed to convert}
\PYG{c}{\PYGZsh{} the raw input flat images into a single stacked and normalized flat image.}
\PYG{c}{\PYGZsh{} This output processed flat is stored on disk using storeProcessedFlat and}
\PYG{c}{\PYGZsh{} has a name equal to the name of the first input flat image with \PYGZdq{}\PYGZus{}flat.fits\PYGZdq{}}
\PYG{c}{\PYGZsh{} appended.}

\PYG{n}{p}\PYG{o}{.}\PYG{n}{prepare}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{addDQ}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{addVAR}\PYG{p}{(}\PYG{n}{read\PYGZus{}noise}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{display}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{overscanCorrect}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{biasCorrect}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{ADUToElectrons}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{addVAR}\PYG{p}{(}\PYG{n}{poisson\PYGZus{}noise}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{addToList}\PYG{p}{(}\PYG{n}{purpose}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{forStack}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{getList}\PYG{p}{(}\PYG{n}{purpose}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{forStack}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{stackFlats}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{normalizeFlat}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{storeProcessedFlat}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

The Demo recipe is named \code{reduceDemo} and contains the instruction set:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c}{\PYGZsh{} reduceDemo}

\PYG{n}{p}\PYG{o}{.}\PYG{n}{prepare}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{addDQ}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{addVAR}\PYG{p}{(}\PYG{n}{read\PYGZus{}noise}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{overscanCorrect}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{biasCorrect}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{ADUToElectrons}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{addVAR}\PYG{p}{(}\PYG{n}{poisson\PYGZus{}noise}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{flatCorrect}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{makeFringe}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{fringeCorrect}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{mosaicDetectors}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{detectSources}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{addToList}\PYG{p}{(}\PYG{n}{purpose}\PYG{o}{=}\PYG{n}{forStack}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{getList}\PYG{p}{(}\PYG{n}{purpose}\PYG{o}{=}\PYG{n}{forStack}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{alignAndStack}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{detectSources}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{p}\PYG{o}{.}\PYG{n}{measureIQ}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

For the curious, the standard bias and flat recipes are found in
\code{???} and the demo recipe is in
\code{???demos/}.  You do not really need that information
as the system will find them on its own.


\section{The Demo}
\label{appendices/appendix_demo:the-demo}
The images will be displayed at times.  Therefore, start ds9:

\begin{Verbatim}[commandchars=\\\{\}]
ds9 \PYGZam{}
\end{Verbatim}


\subsection{The Processed Bias}
\label{appendices/appendix_demo:the-processed-bias}
The first step is to create the processed bias.  We are using the standard
recipe.  The system will recognize the inputs as GMOS biases and call the
appropriate recipe automatically.

The biases were taken on different dates
around the time of the science observations.  For convenience, we will use
a file with the list of datasets as input instead of listing all the input
datasets individually.  We will use a tool named \code{typewalk} to painlessly
create the list.

\begin{Verbatim}[commandchars=\\\{\}]
cd \PYGZlt{}your\PYGZus{}path\PYGZgt{}/gemini\PYGZus{}python\PYGZus{}datapkg\PYGZhy{}X1/playground

typewalk \PYGZhy{}\PYGZhy{}types GMOS BIAS \PYGZhy{}\PYGZhy{}dir ../data\PYGZus{}for\PYGZus{}reduce\PYGZus{}demo \PYGZhy{}o bias.list

reduce @bias.list
\end{Verbatim}

This creates the processed bias, \code{N20120202S0955\_bias.fits}.  The output suffix
\code{\_bias} is the indicator that this is a processed bias.  All processed calibrations
are also stored in \code{./calibrations/storedcals/} for safe keeping.

If you wish to see what the processed bias looks like:

\begin{Verbatim}[commandchars=\\\{\}]
reduce N20120202S0955\PYGZus{}bias.fits \PYGZhy{}r display
\end{Verbatim}

\emph{Note: This will issue an error about the file already existing.  Ignore it.
The explanation of what is going on is beyond the scope of this demo.  We
will fix this, eventually.  Remember that this is a release of software meant
for internal use; there are still plenty of issues to be resolved.}


\subsection{The Processed Flat}
\label{appendices/appendix_demo:the-processed-flat}
Next we create a processed flat.  We will use the processed bias we have
just created.  The system will recognize the inputs as GMOS twilight flats and
call the appropriate recipe automatically.

The ``public'' RecipeSystem does not yet have a Local Calibration Server.  Therefore,
we will need to specify the processed bias we want to use on the \emph{reduce} command
line.  For information only, internally the QA pipeline at the summit uses a
central calibration server and the most appropriate processed calibrations available
are selected and retrieved automatically.  We hope to be able to offer a ``local'',
end-user version of this system in the future.  For now, calibrations must be
specified on the command line.

For the flats, we do not really need a list, we can use wild cards:

\begin{Verbatim}[commandchars=\\\{\}]
reduce ../data\PYGZus{}for\PYGZus{}reduce\PYGZus{}demo/N20120123*.fits \PYGZbs{}
   \PYGZhy{}\PYGZhy{}user\PYGZus{}cal N20120202S0955\PYGZus{}bias.fits \PYGZhy{}p clobber=True;
\end{Verbatim}

This creates the processed flat, \code{N20120123S0123\_flat.fits}.  The output suffix
\code{\_flat} is the indictor that this is a processed flat.  The processed flat is also
stored in \code{./calibrations/storedcals/} for safe keeping.

The \code{clobber} parameter is set to True to allow the system to overwrite the final
output.  By default, the system refuses to overwrite an output file.

If you wish to see what the processed flat looks like:

\begin{Verbatim}[commandchars=\\\{\}]
reduce N20120123S0123\PYGZus{}flat.fits \PYGZhy{}r display
\end{Verbatim}


\subsection{The Science Frames}
\label{appendices/appendix_demo:the-science-frames}
We now have all the pieces required to reduce the science frames.  This time,
instead of using the standard QA recipe, we will use the Demo recipe.  Again,
we will specify the processed calibrations, bias and flat, we wish to use.

\begin{Verbatim}[commandchars=\\\{\}]
reduce ../data\PYGZus{}for\PYGZus{}reduce\PYGZus{}demo/N20120203S028?.fits \PYGZbs{}
   \PYGZhy{}\PYGZhy{}user\PYGZus{}cal N20120202S0955\PYGZus{}bias.fits N20120123S0123\PYGZus{}flat.fits \PYGZbs{}
   \PYGZhy{}r reduceDemo \PYGZhy{}p clobber=True
\end{Verbatim}

The demo data was obtained with the z' filter, therefore the images contain fringing.
The \code{makeFringe} and \code{fringeCorrect} primitives are filter-aware, they will do
something only when the data is from a filter that produces fringing, like the z'
filter.  The processed fringe that is created is stored with the other processed
calibrations in \code{./calibrations/storedcals/} and it is named
\code{N20120203S0281\_fringe.fits}. The \code{\_fringe} suffix indicates a processed fringe.

The last primitive in the recipe is \code{measureIQ} which is one of the QA metrics
primitives used at night by the QA pipeline.  The primitive selects stars in
the field and measures the average seeing and ellipticity.  The image it runs
on is displayed and the selected stars are circled for visual inspections.

The fully processed stacked science image is \code{N20120203S0281\_iqMeasured.fits}.
By default, the suffix of the final image is set by the last primitive run
on the data, in this case \code{measureIQ}.

This default naming can be confusing.  If you wish to set the suffix of the
final image yourself, use \code{-{-}suffix  \_myfinalsuffix}.


\subsection{Clean up}
\label{appendices/appendix_demo:clean-up}
It is good practice to reset the RecipeSystem state when you are done:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{superclean} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{safe}
\end{Verbatim}

Your files will stay there, only some hidden RecipeSystem directories
and files will be deleted.


\section{Limitations}
\label{appendices/appendix_demo:limitations}
The X1 version of the RecipeSystem has not been vetted for Science Quality.
Use ONLY for quick look purposes.

The RecipeSystem currently does not handle memory usage in a very smart way.
The number of files one can pass on to \code{reduce} is directly limited by the
memory of the user's computer.  This demo ran successfully on a Mac laptop
with 4 GB of memory.


\chapter{Class Reduce: Settable properties and attributes}
\label{appendices/reduce_properties:class-reduce-settable-properties-and-attributes}\label{appendices/reduce_properties::doc}\label{appendices/reduce_properties:props}
The public interface on an instance of the Reduce() class provides a
number of properties and attributes that allow the user to set and reset
options as they might through the reduce command line interface. The following
table is an enumerated set of those attributes.

An instance of Reduce() provides the following attributes. (Note: defaults
are not necessarily indicative of the actual type that is expected on
the instance. Use the type specified in the type column.):

\begin{Verbatim}[commandchars=\\\{\}]
Attribute              Python type         Default
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
displayflags           \PYGZlt{}type \PYGZsq{}bool\PYGZsq{}\PYGZgt{}        False
files                  \PYGZlt{}type \PYGZsq{}list\PYGZsq{}\PYGZgt{}        []
context                \PYGZlt{}type \PYGZsq{}str\PYGZsq{}\PYGZgt{}         None
logfile                \PYGZlt{}type \PYGZsq{}str\PYGZsq{}\PYGZgt{}         \PYGZsq{}reduce.log\PYGZsq{}
loglevel               \PYGZlt{}type \PYGZsq{}str\PYGZsq{}\PYGZgt{}         \PYGZsq{}stdinfo\PYGZsq{}
logmode                \PYGZlt{}type \PYGZsq{}str\PYGZsq{}\PYGZgt{}         \PYGZsq{}standard\PYGZsq{}
recipename             \PYGZlt{}type \PYGZsq{}str\PYGZsq{}\PYGZgt{}         None
suffix                 \PYGZlt{}type \PYGZsq{}str\PYGZsq{}\PYGZgt{}         None
user\PYGZus{}cal               \PYGZlt{}type \PYGZsq{}str\PYGZsq{}\PYGZgt{}         None
userparam              \PYGZlt{}type \PYGZsq{}list\PYGZsq{}\PYGZgt{}        None
\end{Verbatim}


\section{Examples}
\label{appendices/reduce_properties:examples}
Setting attributes on a Reduce object:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce} \PYG{o}{=} \PYG{n}{ReduceNH}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{logfile} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{my\PYGZus{}reduction.log}\PYG{l+s}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{recipe} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{recipe.my\PYGZus{}recipe}\PYG{l+s}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{files} \PYG{o}{=} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{UVW.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{XYZ.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}
\end{Verbatim}

Or in other pythonic ways:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{file\PYGZus{}list} \PYG{o}{=} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{FOO.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{BAR.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{files}\PYG{o}{.}\PYG{n}{extend}\PYG{p}{(}\PYG{n}{file\PYGZus{}list}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{files}
\PYG{g+go}{[\PYGZsq{}UVW.fits\PYGZsq{}, \PYGZsq{}XYZ.fits\PYGZsq{}, \PYGZsq{}FOO.fits\PYGZsq{}, \PYGZsq{}BAR.fits\PYGZsq{}]}
\end{Verbatim}

Users wishing to pass primtive parameters to the recipe\_system need only set
the one (1) attribute, \code{userparam}, on the Reduce instance:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{userparam} \PYG{o}{=} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{clobber=True}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}
\end{Verbatim}

This is the API equivalent to the command line option:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} reduce \PYGZhy{}p clobber=True [...]
\end{Verbatim}

For muliple primitive parameters, the `userparam' attribute is a list of
`par=val' strings, as in:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{reduce}\PYG{o}{.}\PYG{n}{userparam} \PYG{o}{=} \PYG{p}{[} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{par1=val1}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{par2=val2}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.} \PYG{p}{]}
\end{Verbatim}


\section{Example function}
\label{appendices/reduce_properties:example-function}
The following function shows a potential usage of class Reduce. When
conditions are met, the function \code{reduce\_conditions\_met()} is called
passing several lists of files, \code{procfiles} (a list of lists of fits
files). Here, each list of \code{procfiles} is then passed to the internal
\code{launch\_reduce()} function.

\begin{Verbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{k+kn}{from} \PYG{n+nn}{gempy.utils} \PYG{k+kn}{import} \PYG{n}{logutils}
\PYG{k+kn}{from} \PYG{n+nn}{recipe\PYGZus{}systenm.reduction.coreReduce} \PYG{k+kn}{import} \PYG{n}{Reduce}

\PYG{k}{def} \PYG{n+nf}{reduce\PYGZus{}conditions\PYGZus{}are\PYGZus{}met}\PYG{p}{(}\PYG{n}{procfiles}\PYG{p}{,} \PYG{n}{control\PYGZus{}options}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{reduce\PYGZus{}object} \PYG{o}{=} \PYG{n}{Reduce}\PYG{p}{(}\PYG{p}{)}
    \PYG{n}{reduce\PYGZus{}object}\PYG{o}{.}\PYG{n}{logfile} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{my\PYGZus{}reduce.log}\PYG{l+s}{\PYGZsq{}}
    \PYG{c}{\PYGZsh{} write logfile only, no stdout.}
    \PYG{n}{reduce\PYGZus{}object}\PYG{o}{.}\PYG{n}{logmode} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{quiet}\PYG{l+s}{\PYGZsq{}}
    \PYG{n}{reduce\PYGZus{}object}\PYG{o}{.}\PYG{n}{userparam} \PYG{o}{=} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{clobber=True}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}

    \PYG{n}{logutils}\PYG{o}{.}\PYG{n}{config}\PYG{p}{(}\PYG{n}{file\PYGZus{}name}\PYG{o}{=}\PYG{n}{reduce\PYGZus{}object}\PYG{o}{.}\PYG{n}{logfile}\PYG{p}{,}
                    \PYG{n}{mode}\PYG{o}{=}\PYG{n}{reduce\PYGZus{}object}\PYG{o}{.}\PYG{n}{logmode}\PYG{p}{,}
                    \PYG{n}{console\PYGZus{}lvl}\PYG{o}{=}\PYG{n}{reduce\PYGZus{}object}\PYG{o}{.}\PYG{n}{loglevel}\PYG{p}{)}

    \PYG{k}{def} \PYG{n+nf}{launch\PYGZus{}reduce}\PYG{p}{(}\PYG{n}{datasets}\PYG{p}{,} \PYG{n}{recipe}\PYG{o}{=}\PYG{n+nb+bp}{None}\PYG{p}{,} \PYG{n}{upload}\PYG{o}{=}\PYG{n+nb+bp}{False}\PYG{p}{)}\PYG{p}{:}
        \PYG{n}{reduce\PYGZus{}object}\PYG{o}{.}\PYG{n}{files} \PYG{o}{=} \PYG{n}{datasets}
        \PYG{k}{if} \PYG{n}{recipe}\PYG{p}{:}
            \PYG{n}{reduce\PYGZus{}object}\PYG{o}{.}\PYG{n}{recipename} \PYG{o}{=} \PYG{n}{recipe}
        \PYG{k}{if} \PYG{n}{upload}\PYG{p}{:}
            \PYG{n}{reduce\PYGZus{}object}\PYG{o}{.}\PYG{n}{context} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{qa, upload}\PYG{l+s}{\PYGZsq{}}
        \PYG{k}{else}\PYG{p}{:}
            \PYG{n}{reduce\PYGZus{}object}\PYG{o}{.}\PYG{n}{context} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{qa}\PYG{l+s}{\PYGZsq{}}
        \PYG{n}{reduce\PYGZus{}object}\PYG{o}{.}\PYG{n}{runr}\PYG{p}{(}\PYG{p}{)}
        \PYG{k}{return}

    \PYG{k}{for} \PYG{n}{files} \PYG{o+ow}{in} \PYG{n}{procfiles}\PYG{p}{:}
        \PYG{c}{\PYGZsh{} Use a different recipe if FOO.fits is present}
        \PYG{k}{if} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{FOO.fits}\PYG{l+s}{\PYGZdq{}} \PYG{o+ow}{in} \PYG{n}{files}\PYG{p}{:}
            \PYG{n}{launch\PYGZus{}reduce}\PYG{p}{(}\PYG{n+nb}{sorted}\PYG{p}{(}\PYG{n}{files}\PYG{p}{)}\PYG{p}{,} \PYG{n}{recipe}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{recipe.FOO}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
        \PYG{k}{else}\PYG{p}{:}
            \PYG{n}{launch\PYGZus{}reduce}\PYG{p}{(}\PYG{n+nb}{sorted}\PYG{p}{(}\PYG{n}{files}\PYG{p}{)}\PYG{p}{,} \PYG{n}{upload}\PYG{o}{=}\PYG{n}{control\PYGZus{}options}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{upload}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}

    \PYG{k}{return}

\PYG{n}{procfiles} \PYG{o}{=} \PYG{p}{[} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{FOO.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{BAR.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,}
              \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{UVW.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{XYZ.fits}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}
           \PYG{p}{]}
\PYG{k}{if} \PYG{n}{conditions\PYGZus{}are\PYGZus{}met}\PYG{p}{:}
    \PYG{n}{reduce\PYGZus{}conditions\PYGZus{}are\PYGZus{}met}\PYG{p}{(}\PYG{n}{procfiles}\PYG{p}{)}
\end{Verbatim}

Readers will see here that calling \code{reduce\_conditions\_are\_met()} without the
\code{control\_options} parameter will result in the \code{running\_contexts} attribute
being set to \code{'qa'}.



\renewcommand{\indexname}{Index}
\printindex
\end{document}
